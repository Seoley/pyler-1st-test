{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b495b9-2635-4ca4-923d-3df8fb57d2df",
   "metadata": {},
   "source": [
    "# 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0b473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modules import ContrastiveLoss, DummyFlickerDataset, DummyHardNegativeDataset, DummyTextToTextDataset\n",
    "from modules import open_image, get_logger\n",
    "from modules.models import ClipModelRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f419a3a-8fa6-47d4-b2ac-1d30139cb360",
   "metadata": {},
   "source": [
    "# 2. Load model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9f6cea-8592-471d-9578-a45b9bc11cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "dataset_size = 32\n",
    "\n",
    "model = ClipModelRetriever(device)\n",
    "\n",
    "criterion = ContrastiveLoss().to(device)\n",
    "optimizer = optim.Adam(model.model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90d998-f08a-4a71-a582-43f7102548c2",
   "metadata": {},
   "source": [
    "# 3. Modality-aware hard negative mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a618fef6-22e3-464c-8436-0697b4a56217",
   "metadata": {},
   "source": [
    "### 3.1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b2f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 15:40:05 - INFO - Initializing DummyFlickerDataset...\n",
      "2025-03-03 15:40:05 - INFO - Initializing DummyFlickerDataset...\n",
      "2025-03-03 15:40:05 - INFO - Initializing DummyHardNegativeDataset...\n",
      "2025-03-03 15:40:05 - INFO - Initializing Multimodal Hard Negative Mining Controler.\n",
      "2025-03-03 15:40:05 - INFO - Initializing Multimodal Hard Negative Mining Controler.\n"
     ]
    }
   ],
   "source": [
    "dataset = DummyFlickerDataset(dataset_size)\n",
    "hard_negative_dataset = DummyHardNegativeDataset(model=model, size=dataset_size)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    query_index = [item[0] for item in batch]\n",
    "    document_index = [item[1] for item in batch]\n",
    "    documnet_type = [item[2] for item in batch]\n",
    "    negative_indices = [item[3] for item in batch]\n",
    "\n",
    "    return query_index, document_index, documnet_type, negative_indices \n",
    "\n",
    "dataloader = DataLoader(hard_negative_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94578e97-d153-4f13-a529-b8514f8c459a",
   "metadata": {},
   "source": [
    "### 3.2. Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e7fcbf-d8ce-413d-880e-feda751aec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 15:40:49 - INFO - Start Modality-aware hard negative finetuning...\n",
      "Training: 100%|██████████| 8/8 [00:09<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 4.133142292499542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:07<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 3.7724913954734802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:07<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 3.691261053085327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:08<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 3.6880630254745483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:08<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 3.702912151813507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 3.695889800786972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:08<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 3.6901063323020935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:08<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 3.684810996055603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 3.680789291858673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:08<00:00,  1.03s/it]\n",
      "2025-03-03 15:42:12 - INFO - Finish Modality-aware hard negative finetuning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 3.6789028644561768\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start Modality-aware hard negative finetuning...\")\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    with tqdm(dataloader, desc=f\"Training\", dynamic_ncols=True) as epoch_bar:\n",
    "        for query_index_set, document_index_set, documnet_type_set, negative_indices_set in epoch_bar:\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss = 0\n",
    "            for query_index, document_index, documnet_type, negative_indices in zip(query_index_set, document_index_set, documnet_type_set, negative_indices_set):\n",
    "                query = dataset[query_index][0]\n",
    "\n",
    "                outputs = model.text_encoder(texts=[query])\n",
    "                \n",
    "                positive_emb = torch.Tensor([]).to(device)\n",
    "                \n",
    "                if documnet_type == \"text\":\n",
    "                    positive_sample = dataset[document_index][0]\n",
    "                    positive_emb = model.text_encoder(texts=positive_sample)\n",
    "                else:\n",
    "                    positive_sample = dataset[document_index][1]\n",
    "                    positive_image = open_image(positive_sample)\n",
    "                    positive_emb = model.image_encoder(images=positive_image)   \n",
    "                \n",
    "                \n",
    "                neg_text_emb = torch.Tensor([]).to(device)\n",
    "                neg_image_emb = torch.Tensor([]).to(device)\n",
    "                \n",
    "                if negative_indices[\"text\"]:\n",
    "                    neg_text_samples = dataset[negative_indices[\"text\"]][0].to_list()\n",
    "                    neg_text_emb = model.text_encoder(texts=neg_text_samples)\n",
    "                \n",
    "                if negative_indices[\"image\"]:\n",
    "                    neg_image_samples = dataset[negative_indices[\"image\"]][1].to_list()\n",
    "                    neg_images = [open_image(image) for image in neg_image_samples]\n",
    "                    neg_image_emb = model.image_encoder(images=neg_images)\n",
    "                \n",
    "                negative_emb = torch.concat([neg_text_emb, neg_image_emb], dim=0)\n",
    "\n",
    "                loss = criterion(outputs, positive_emb, negative_emb)\n",
    "\n",
    "                batch_loss = batch_loss + loss\n",
    "\n",
    "            total_loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {i+1}: {total_loss / len(hard_negative_dataset)}\")\n",
    "\n",
    "\n",
    "logger.info(\"Finish Modality-aware hard negative finetuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618005e-4f18-4659-9269-b33307c276e1",
   "metadata": {},
   "source": [
    "# 4. Text-to-Text finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ea4dc-7710-434e-a3f8-9661da784326",
   "metadata": {},
   "source": [
    "### 4.1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4e3d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 15:42:12 - INFO - Initializing DummyFlickerDataset...\n",
      "2025-03-03 15:42:12 - INFO - Initializing DummyFlickerDataset...\n",
      "2025-03-03 15:42:13 - INFO - Initializing DummyHardNegativeDataset...\n",
      "2025-03-03 15:42:13 - INFO - Initializing Multimodal Hard Negative Mining Controler.\n",
      "2025-03-03 15:42:13 - INFO - Initializing Multimodal Hard Negative Mining Controler.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 8\n",
    "\n",
    "dataset = DummyFlickerDataset(size=dataset_size)\n",
    "finetuning_dataset = DummyTextToTextDataset(model=model, size=dataset_size)\n",
    "\n",
    "def collate_fn_finetuning(batch):\n",
    "    query_index = [item[0] for item in batch]\n",
    "    document_index = [item[1] for item in batch]\n",
    "    documnet_type = [item[2] for item in batch]\n",
    "    negative_indices = [item[3] for item in batch]\n",
    "\n",
    "    return query_index, document_index, documnet_type, negative_indices \n",
    "\n",
    "finetuning_dataloader = DataLoader(finetuning_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_finetuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904feee-d0bb-4571-ae79-6d7e7da595ce",
   "metadata": {},
   "source": [
    "### 4.2. Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05516452-d002-492a-b897-cd965fb9e37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 15:42:14 - INFO - Start text-to-text finetuning...\n",
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 3.0440885424613953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 3.0439098477363586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 3.0437732338905334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 3.0438162088394165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 3.0435999631881714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 3.0433127880096436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 3.0429492592811584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 3.0424980521202087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 3.0418633818626404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:01<00:00,  2.24it/s]\n",
      "2025-03-03 15:42:31 - INFO - Finish text-to-text finetuning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 3.0408228635787964\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start text-to-text finetuning...\")\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    with tqdm(finetuning_dataloader, desc=f\"Training\", dynamic_ncols=True) as epoch_bar:\n",
    "        for query_index_set, document_index_set, documnet_type_set, negative_indices_set in epoch_bar:\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss = 0\n",
    "            for query_index, document_index, documnet_type, negative_indices in zip(query_index_set, document_index_set, documnet_type_set, negative_indices_set):\n",
    "                query = dataset[query_index][0]\n",
    "\n",
    "                outputs = model.text_encoder(texts=[query])\n",
    "                \n",
    "                positive_emb = torch.Tensor([]).to(device)\n",
    "                \n",
    "                positive_sample = dataset[document_index][0]\n",
    "                positive_emb = model.text_encoder(texts=positive_sample)\n",
    "                \n",
    "                neg_text_emb = torch.Tensor([]).to(device)\n",
    "                \n",
    "                if negative_indices[\"text\"]:\n",
    "                    neg_text_samples = dataset[negative_indices[\"text\"]][0].to_list()\n",
    "                    neg_text_emb = model.text_encoder(texts=neg_text_samples)\n",
    "\n",
    "                negative_emb = neg_text_emb\n",
    "                \n",
    "                loss = criterion(outputs, positive_emb, negative_emb)\n",
    "\n",
    "                batch_loss = batch_loss + loss\n",
    "\n",
    "            total_loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {i+1}: {total_loss / len(hard_negative_dataset)}\")\n",
    "\n",
    "logger.info(\"Finish text-to-text finetuning.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02a00062-5971-49b7-9896-d73df2fea579",
   "metadata": {},
   "source": [
    "# 5. Prompting multimodal LLMS for reranking\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657c7396-3d8a-4ca8-becb-c5ffb4e29d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ZeroShotReranker():\n",
    "    def __init__(self):\n",
    "        model_name = \"gpt2\"  \n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def calculate_score(self, query: str, candidate):\n",
    "        query = \"Question: What is this person doing?\"\n",
    "        candidate = \"Running on the beach.\"\n",
    "        prompt = f\"{query}\\nAnswer: {candidate}\\nDoes the answer correctly answer the question? True or False\"\n",
    "        \n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits \n",
    "        \n",
    "        true_token_id = self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(\" True\")[0])\n",
    "        false_token_id = self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(\" False\")[0])\n",
    "        \n",
    "        true_logit = logits[0, -1, true_token_id]\n",
    "        false_logit = logits[0, -1, false_token_id]\n",
    "        \n",
    "        probs = F.softmax(torch.tensor([true_logit, false_logit]), dim=0)\n",
    "        true_prob = probs[0].item()\n",
    "        return true_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "199ff7b4-00a5-4b5e-9672-e42ebe18b8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 확률 (관련성 점수): 0.5386\n"
     ]
    }
   ],
   "source": [
    "query = \"Question: What is this person doing?\"\n",
    "candidate = \"Running on the beach.\"\n",
    "\n",
    "reranker = ZeroShotReranker()\n",
    "\n",
    "true_prob = reranker.calculate_score(query, candidate)\n",
    "print(f\"True 확률 (관련성 점수): {true_prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
